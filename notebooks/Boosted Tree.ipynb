{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lc = LabelEncoder()\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from numpy import arange\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, plot_roc_curve, roc_auc_score\n",
    "\n",
    "#import precision and recall\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Trick to widen the screen\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "#Widens the code landscape \n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataAnalyst_X_Test.csv\")\n",
    "X_train = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataAnalyst_X_Train.csv\")\n",
    "y_test = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataAnalyst_y_Test.csv\")\n",
    "y_train = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataAnalyst_y_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decTree = GradientBoostingClassifier(learning_rate=0.1)\n",
    "decTree.fit(X_train,y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Initial Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "#Print the scores we calculated earlier in this block\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for the first draft model\n",
    "y_pred_prob = decTree.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.plot(fpr, tpr, label='Gradient Boosted Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC Curve')\n",
    "plt.show();\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, decTree.predict(X_test))\n",
    "\n",
    "# roc auc score\n",
    "log_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "roc_auc_format = 'ROC AUC Score: {0:.4f}'.format(log_roc_auc)\n",
    "print(roc_auc_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use grid search cv to prune the decision tree\n",
    "# grid={'learning_rate': [.01,.05,.1],\"max_depth\" : [3, 4, 5, 6],\"max_leaf_nodes\" : [2, 3, 4, 8], \n",
    "#       'n_estimators': [50,100,150]}\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state = 42)\n",
    "# model_gs=GridSearchCV(model,grid,cv=10)\n",
    "# with tqdm(total=len(grid)) as pbar:\n",
    "#     model_gs = model_gs.fit(X_train, y_train)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# print(\"tuned hyperparameters :(best parameters) \",model_gs.best_params_)\n",
    "# print(\"accuracy :\",model_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit new model with best parameters determined by gscv on the training data\n",
    "decTree_gs = GradientBoostingClassifier(random_state =42, learning_rate =0.05, max_depth =3, max_leaf_nodes =4, n_estimators =100)\n",
    "decTree_gs.fit(X_train, y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree_gs.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree_gs.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "decTree_precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "decTree_recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "\n",
    "#Print the scores\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataEngineer_X_Test.csv\")\n",
    "X_train = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataEngineer_X_Train.csv\")\n",
    "y_test = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataEngineer_y_Test.csv\")\n",
    "y_train = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataEngineer_y_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decTree = GradientBoostingClassifier(learning_rate=0.1)\n",
    "decTree.fit(X_train,y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Initial Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "#Print the scores we calculated earlier in this block\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for the first draft model\n",
    "y_pred_prob = decTree.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.plot(fpr, tpr, label='Gradient Boosted Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC Curve')\n",
    "plt.show();\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, decTree.predict(X_test))\n",
    "\n",
    "# roc auc score\n",
    "log_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "roc_auc_format = 'ROC AUC Score: {0:.4f}'.format(log_roc_auc)\n",
    "print(roc_auc_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use grid search cv to prune the decision tree\n",
    "# grid={'learning_rate': [.01,.05,.1],\"max_depth\" : [3, 4, 5, 6],\"max_leaf_nodes\" : [2, 3, 4, 8], \n",
    "#       'n_estimators': [50,100,150]}\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state = 42)\n",
    "# model_gs=GridSearchCV(model,grid,cv=10)\n",
    "# with tqdm(total=len(grid)) as pbar:\n",
    "#     model_gs = model_gs.fit(X_train, y_train)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# print(\"tuned hyperparameters :(best parameters) \",model_gs.best_params_)\n",
    "# print(\"accuracy :\",model_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit new model with best parameters determined by gscv on the training data\n",
    "decTree_gs = GradientBoostingClassifier(random_state =42, learning_rate =0.01, max_depth =5, max_leaf_nodes =8, n_estimators =100)\n",
    "decTree_gs.fit(X_train, y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree_gs.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree_gs.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "decTree_precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "decTree_recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "\n",
    "#Print the scores\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataScientist_X_Test.csv\")\n",
    "X_train = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataScientist_X_Train.csv\")\n",
    "y_test = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataScientist_y_Test.csv\")\n",
    "y_train = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\DataScientist_y_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decTree = GradientBoostingClassifier(learning_rate=0.1)\n",
    "decTree.fit(X_train,y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Initial Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "#Print the scores we calculated earlier in this block\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for the first draft model\n",
    "y_pred_prob = decTree.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.plot(fpr, tpr, label='Gradient Boosted Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC Curve')\n",
    "plt.show();\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, decTree.predict(X_test))\n",
    "\n",
    "# roc auc score\n",
    "log_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "roc_auc_format = 'ROC AUC Score: {0:.4f}'.format(log_roc_auc)\n",
    "print(roc_auc_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use grid search cv to prune the decision tree\n",
    "# grid={'learning_rate': [.01,.05,.1],\"max_depth\" : [3, 4, 5, 6],\"max_leaf_nodes\" : [2, 3, 4, 8], \n",
    "#       'n_estimators': [50,100,150]}\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state = 42)\n",
    "# model_gs=GridSearchCV(model,grid,cv=10)\n",
    "# with tqdm(total=len(grid)) as pbar:\n",
    "#     model_gs = model_gs.fit(X_train, y_train)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# print(\"tuned hyperparameters :(best parameters) \",model_gs.best_params_)\n",
    "# print(\"accuracy :\",model_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit new model with best parameters determined by gscv on the training data\n",
    "decTree_gs = GradientBoostingClassifier(random_state =42, learning_rate =0.01, max_depth =3, max_leaf_nodes =8, n_estimators =100)\n",
    "decTree_gs.fit(X_train, y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree_gs.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree_gs.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "decTree_precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "decTree_recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "\n",
    "#Print the scores\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\Machine_Learning_Engineer_X_Test.csv\")\n",
    "X_train = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\Machine_Learning_Engineer_y_Test.csv\")\n",
    "y_test = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\Machine_Learning_Engineer_y_Train.csv\")\n",
    "y_train = pd.read_csv(r\"C:\\Users\\Danny Farone\\Documents\\GitHub\\Data-Science-Job-Salaries\\data\\processed\\Machine_Learning_Engineerr_X_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decTree = GradientBoostingClassifier(learning_rate=0.1)\n",
    "decTree.fit(X_train,y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Initial Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "#Print the scores we calculated earlier in this block\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for the first draft model\n",
    "y_pred_prob = decTree.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.plot(fpr, tpr, label='Gradient Boosted Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC Curve')\n",
    "plt.show();\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, decTree.predict(X_test))\n",
    "\n",
    "# roc auc score\n",
    "log_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "roc_auc_format = 'ROC AUC Score: {0:.4f}'.format(log_roc_auc)\n",
    "print(roc_auc_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use grid search cv to prune the decision tree\n",
    "# grid={'learning_rate': [.01,.05,.1],\"max_depth\" : [3, 4, 5, 6],\"max_leaf_nodes\" : [2, 3, 4, 8], \n",
    "#       'n_estimators': [50,100,150]}\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state = 42)\n",
    "# model_gs=GridSearchCV(model,grid,cv=10)\n",
    "# with tqdm(total=len(grid)) as pbar:\n",
    "#     model_gs = model_gs.fit(X_train, y_train)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# print(\"tuned hyperparameters :(best parameters) \",model_gs.best_params_)\n",
    "# print(\"accuracy :\",model_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit new model with best parameters determined by gscv on the training data\n",
    "decTree_gs = GradientBoostingClassifier(random_state =42, learning_rate =0.01, max_depth =3, max_leaf_nodes =2, n_estimators =50)\n",
    "decTree_gs.fit(X_train, y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree_gs.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree_gs.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "decTree_precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "decTree_recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "\n",
    "#Print the scores\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
