{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numexpr==2.7.3 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scipy==1.5.2 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pandas-profiling[notebook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas-profiling networkx --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dfaro\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "<ipython-input-1-92f7d995aaef>:3: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  import pandas_profiling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import ydata_profiling\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lc = LabelEncoder()\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from numpy import arange\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, plot_roc_curve, roc_auc_score\n",
    "\n",
    "#import precision and recall\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Trick to widen the screen\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "#Widens the code landscape \n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns',500)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the masterquote dataset into a dataframe named df\n",
    "df = pd.read_csv('ds_salaries_external.csv', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>98000</td>\n",
       "      <td>USD</td>\n",
       "      <td>98000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>EX</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>IN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>100000</td>\n",
       "      <td>USD</td>\n",
       "      <td>100000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>11000000</td>\n",
       "      <td>HUF</td>\n",
       "      <td>36259</td>\n",
       "      <td>HU</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>EN</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>55000</td>\n",
       "      <td>USD</td>\n",
       "      <td>55000</td>\n",
       "      <td>US</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>2021</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>81000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>95746</td>\n",
       "      <td>DE</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>2022</td>\n",
       "      <td>EN</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>150000</td>\n",
       "      <td>USD</td>\n",
       "      <td>150000</td>\n",
       "      <td>AU</td>\n",
       "      <td>100</td>\n",
       "      <td>AU</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>2022</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>50000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>54957</td>\n",
       "      <td>GR</td>\n",
       "      <td>0</td>\n",
       "      <td>GR</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>2022</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>50000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>54957</td>\n",
       "      <td>GR</td>\n",
       "      <td>0</td>\n",
       "      <td>GR</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>2022</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>240000</td>\n",
       "      <td>CNY</td>\n",
       "      <td>37236</td>\n",
       "      <td>US</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>606 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     work_year experience_level employment_type                  job_title  \\\n",
       "0         2020               MI              FT               Data Analyst   \n",
       "1         2021               EX              FT               Data Analyst   \n",
       "2         2021               MI              FT               Data Analyst   \n",
       "3         2021               MI              FT               Data Analyst   \n",
       "4         2021               EN              FT               Data Analyst   \n",
       "..         ...              ...             ...                        ...   \n",
       "601       2021               MI              FT  Machine Learning Engineer   \n",
       "602       2022               EN              FT  Machine Learning Engineer   \n",
       "603       2022               MI              FT  Machine Learning Engineer   \n",
       "604       2022               MI              FT  Machine Learning Engineer   \n",
       "605       2022               MI              FT  Machine Learning Engineer   \n",
       "\n",
       "       salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0       98000             USD          98000                 US             0   \n",
       "1      150000             USD         150000                 IN           100   \n",
       "2      100000             USD         100000                 US           100   \n",
       "3    11000000             HUF          36259                 HU            50   \n",
       "4       55000             USD          55000                 US            50   \n",
       "..        ...             ...            ...                ...           ...   \n",
       "601     81000             EUR          95746                 DE           100   \n",
       "602    150000             USD         150000                 AU           100   \n",
       "603     50000             EUR          54957                 GR             0   \n",
       "604     50000             EUR          54957                 GR             0   \n",
       "605    240000             CNY          37236                 US            50   \n",
       "\n",
       "    company_location company_size  \n",
       "0                 US            M  \n",
       "1                 US            L  \n",
       "2                 US            M  \n",
       "3                 US            L  \n",
       "4                 US            S  \n",
       "..               ...          ...  \n",
       "601               US            S  \n",
       "602               AU            S  \n",
       "603               GR            M  \n",
       "604               GR            M  \n",
       "605               US            L  \n",
       "\n",
       "[606 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 606 entries, 0 to 605\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   work_year           606 non-null    int64 \n",
      " 1   experience_level    606 non-null    object\n",
      " 2   employment_type     606 non-null    object\n",
      " 3   job_title           606 non-null    object\n",
      " 4   salary              606 non-null    int64 \n",
      " 5   salary_currency     606 non-null    object\n",
      " 6   salary_in_usd       606 non-null    int64 \n",
      " 7   employee_residence  606 non-null    object\n",
      " 8   remote_ratio        606 non-null    int64 \n",
      " 9   company_location    606 non-null    object\n",
      " 10  company_size        606 non-null    object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 52.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a439e26b034a45817fd6197e8dfb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799f6423a6e840979ae843431b14e805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23c22b7b7c14018adc3411e559982bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e5d50337af4f6abe8d15425fb20a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile.to_file(\"output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['salary'], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at unique values for the categorical variables\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experience_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_experience_level = pd.DataFrame(df['experience_level'].value_counts().reset_index())\n",
    "\n",
    "experience_level_dummies = pd.get_dummies(df['experience_level'])\n",
    "#Concat the dummy variables to the main dataset\n",
    "df = pd.concat([df,experience_level_dummies], axis =1)\n",
    "#and drop the original variable from the data\n",
    "df = df.drop('experience_level', axis = 1)\n",
    "experience_level_dummies.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'EN' : 'Entry_Exp', 'EX' : 'Expert_Exp', 'MI' : 'Mid_Exp', 'SE' : ' Senior_Exp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['employment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['employment_type'])):\n",
    "    if df['employment_type'][i] == 'FT':\n",
    "        df['employment_type'][i] = 1\n",
    "    else:\n",
    "        df['employment_type'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['employment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = pd.DataFrame(df['job_title'].value_counts().reset_index())\n",
    "\n",
    "job_title_dummies = pd.get_dummies(df['job_title'])\n",
    "#Concat the dummy variables to the main dataset \n",
    "df = pd.concat([df, job_title_dummies], axis = 1)\n",
    "#and drop the original variable from the data\n",
    "df = df.drop('job_title', axis = 1)\n",
    "job_title_dummies.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary_currency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USD = []\n",
    "EUR = []\n",
    "GBP = []\n",
    "INR = []\n",
    "Other_Currency = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for currency in df['salary_currency']:\n",
    "    if currency == 'USD':\n",
    "        USD.append(1)\n",
    "        EUR.append(0)\n",
    "        GBP.append(0)\n",
    "        INR.append(0)\n",
    "        Other_Currency.append(0)\n",
    "    elif currency == 'EUR':\n",
    "        USD.append(0)\n",
    "        EUR.append(1)\n",
    "        GBP.append(0)\n",
    "        INR.append(0)\n",
    "        Other_Currency.append(0)\n",
    "    elif currency == 'GBP':\n",
    "        USD.append(0)\n",
    "        EUR.append(0)\n",
    "        GBP.append(1)\n",
    "        INR.append(0)\n",
    "        Other_Currency.append(0)\n",
    "    elif currency == 'INR':\n",
    "        USD.append(0)\n",
    "        EUR.append(0)\n",
    "        GBP.append(0)\n",
    "        INR.append(1)\n",
    "        Other_Currency.append(0)\n",
    "    else:\n",
    "        USD.append(0)\n",
    "        EUR.append(0)\n",
    "        GBP.append(0)\n",
    "        INR.append(0)\n",
    "        Other_Currency.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['USD'] = USD\n",
    "df['EUR'] = EUR\n",
    "df['GBP'] = GBP\n",
    "df['INR'] = INR\n",
    "df['Other_Currency'] = Other_Currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('salary_currency',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['employee_residence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['employee_residence'])):\n",
    "    if df['employee_residence'][i] == 'US':\n",
    "        df['employee_residence'][i] = 1\n",
    "    else:\n",
    "        df['employee_residence'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'employment_type' : 'full_time_employee', 'employee_residence' : 'US_resident'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['company_location'])):\n",
    "    if df['company_location'][i] == 'US':\n",
    "        df['company_location'][i] = 1\n",
    "    else:\n",
    "        df['company_location'][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'company_location' : 'US_location'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_size = pd.DataFrame(df['company_size'].value_counts().reset_index())\n",
    "\n",
    "company_size_dummies = pd.get_dummies(df['company_size'])\n",
    "#Concat the dummy variables to the main dataset \n",
    "df = pd.concat([df, company_size_dummies], axis = 1)\n",
    "#and drop the original variable from the data\n",
    "df = df.drop('company_size', axis = 1)\n",
    "company_size_dummies.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'L' : 'Large_Company', 'M' : 'Midsize_Company', 'S' : 'Small_Company'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('ds_salaries_interim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Data Analyst','Data Engineer','Data Scientist', 'Machine Learning Engineer'], axis = 1)\n",
    "y = df['Data Analyst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decTree = GradientBoostingClassifier(learning_rate=0.1)\n",
    "decTree.fit(X_train,y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Initial Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "#Print the scores we calculated earlier in this block\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for the first draft model\n",
    "y_pred_prob = decTree.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.plot(fpr, tpr, label='Gradient Boosted Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC Curve')\n",
    "plt.show();\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, decTree.predict(X_test))\n",
    "\n",
    "# roc auc score\n",
    "log_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "roc_auc_format = 'ROC AUC Score: {0:.4f}'.format(log_roc_auc)\n",
    "print(roc_auc_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use grid search cv to prune the decision tree\n",
    "# grid={'learning_rate': [.01,.05,.1],\"max_depth\" : [3, 4, 5, 6],\"max_leaf_nodes\" : [2, 3, 4, 8], \n",
    "#       'n_estimators': [50,100,150]}\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state = 42)\n",
    "# model_gs=GridSearchCV(model,grid,cv=10)\n",
    "# with tqdm(total=len(grid)) as pbar:\n",
    "#     model_gs = model_gs.fit(X_train, y_train)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# print(\"tuned hyperparameters :(best parameters) \",model_gs.best_params_)\n",
    "# print(\"accuracy :\",model_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit new model with best parameters determined by gscv on the training data\n",
    "decTree_gs = GradientBoostingClassifier(random_state =42, learning_rate =0.05, max_depth =3, max_leaf_nodes =4, n_estimators =100)\n",
    "decTree_gs.fit(X_train, y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree_gs.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree_gs.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "decTree_precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "decTree_recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "\n",
    "#Print the scores\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Data Analyst','Data Engineer','Data Scientist', 'Machine Learning Engineer'], axis = 1)\n",
    "y = df['Data Engineer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decTree = GradientBoostingClassifier(learning_rate=0.1)\n",
    "decTree.fit(X_train,y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Initial Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "#Print the scores we calculated earlier in this block\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for the first draft model\n",
    "y_pred_prob = decTree.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.plot(fpr, tpr, label='Gradient Boosted Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC Curve')\n",
    "plt.show();\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, decTree.predict(X_test))\n",
    "\n",
    "# roc auc score\n",
    "log_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "roc_auc_format = 'ROC AUC Score: {0:.4f}'.format(log_roc_auc)\n",
    "print(roc_auc_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use grid search cv to prune the decision tree\n",
    "# grid={'learning_rate': [.01,.05,.1],\"max_depth\" : [3, 4, 5, 6],\"max_leaf_nodes\" : [2, 3, 4, 8], \n",
    "#       'n_estimators': [50,100,150]}\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state = 42)\n",
    "# model_gs=GridSearchCV(model,grid,cv=10)\n",
    "# with tqdm(total=len(grid)) as pbar:\n",
    "#     model_gs = model_gs.fit(X_train, y_train)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# print(\"tuned hyperparameters :(best parameters) \",model_gs.best_params_)\n",
    "# print(\"accuracy :\",model_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit new model with best parameters determined by gscv on the training data\n",
    "decTree_gs = GradientBoostingClassifier(random_state =42, learning_rate =0.01, max_depth =5, max_leaf_nodes =8, n_estimators =100)\n",
    "decTree_gs.fit(X_train, y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree_gs.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree_gs.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "decTree_precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "decTree_recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "\n",
    "#Print the scores\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Data Analyst','Data Engineer','Data Scientist', 'Machine Learning Engineer'], axis = 1)\n",
    "y = df['Data Scientist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decTree = GradientBoostingClassifier(learning_rate=0.1)\n",
    "decTree.fit(X_train,y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Initial Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "#Print the scores we calculated earlier in this block\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for the first draft model\n",
    "y_pred_prob = decTree.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.plot(fpr, tpr, label='Gradient Boosted Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC Curve')\n",
    "plt.show();\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, decTree.predict(X_test))\n",
    "\n",
    "# roc auc score\n",
    "log_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "roc_auc_format = 'ROC AUC Score: {0:.4f}'.format(log_roc_auc)\n",
    "print(roc_auc_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use grid search cv to prune the decision tree\n",
    "# grid={'learning_rate': [.01,.05,.1],\"max_depth\" : [3, 4, 5, 6],\"max_leaf_nodes\" : [2, 3, 4, 8], \n",
    "#       'n_estimators': [50,100,150]}\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state = 42)\n",
    "# model_gs=GridSearchCV(model,grid,cv=10)\n",
    "# with tqdm(total=len(grid)) as pbar:\n",
    "#     model_gs = model_gs.fit(X_train, y_train)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# print(\"tuned hyperparameters :(best parameters) \",model_gs.best_params_)\n",
    "# print(\"accuracy :\",model_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit new model with best parameters determined by gscv on the training data\n",
    "decTree_gs = GradientBoostingClassifier(random_state =42, learning_rate =0.01, max_depth =3, max_leaf_nodes =8, n_estimators =100)\n",
    "decTree_gs.fit(X_train, y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree_gs.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree_gs.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "decTree_precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "decTree_recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "\n",
    "#Print the scores\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Data Analyst','Data Engineer','Data Scientist', 'Machine Learning Engineer'], axis = 1)\n",
    "y = df['Machine Learning Engineer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decTree = GradientBoostingClassifier(learning_rate=0.1)\n",
    "decTree.fit(X_train,y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Initial Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "#Print the scores we calculated earlier in this block\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for the first draft model\n",
    "y_pred_prob = decTree.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.plot(fpr, tpr, label='Gradient Boosted Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree ROC Curve')\n",
    "plt.show();\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, decTree.predict(X_test))\n",
    "\n",
    "# roc auc score\n",
    "log_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "roc_auc_format = 'ROC AUC Score: {0:.4f}'.format(log_roc_auc)\n",
    "print(roc_auc_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use grid search cv to prune the decision tree\n",
    "# grid={'learning_rate': [.01,.05,.1],\"max_depth\" : [3, 4, 5, 6],\"max_leaf_nodes\" : [2, 3, 4, 8], \n",
    "#       'n_estimators': [50,100,150]}\n",
    "\n",
    "# model = GradientBoostingClassifier(random_state = 42)\n",
    "# model_gs=GridSearchCV(model,grid,cv=10)\n",
    "# with tqdm(total=len(grid)) as pbar:\n",
    "#     model_gs = model_gs.fit(X_train, y_train)\n",
    "#     pbar.update(1)\n",
    "\n",
    "# print(\"tuned hyperparameters :(best parameters) \",model_gs.best_params_)\n",
    "# print(\"accuracy :\",model_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit new model with best parameters determined by gscv on the training data\n",
    "decTree_gs = GradientBoostingClassifier(random_state =42, learning_rate =0.01, max_depth =3, max_leaf_nodes =2, n_estimators =50)\n",
    "decTree_gs.fit(X_train, y_train)\n",
    "\n",
    "#accuracy of the model on the testing data\n",
    "decTree_score_test = decTree_gs.score(X_test, y_test)\n",
    "#predictions for the model on the testing data\n",
    "decTree_pred_test = decTree_gs.predict(X_test)\n",
    "#Precision of the model on the testing data\n",
    "decTree_precision_test = precision_score(y_test, decTree_pred_test)\n",
    "#Recall of the model on the testing data\n",
    "decTree_recall_test = recall_score(y_test, decTree_pred_test)\n",
    "\n",
    "#Print a simple confusion matrix of the teting data results\n",
    "print(\"Decision Tree confusion matrix:\")\n",
    "print(confusion_matrix(y_test, decTree_pred_test), '\\n')\n",
    "\n",
    "#Print the scores\n",
    "print(\"Accuracy: \", decTree_score_test)\n",
    "print(\"Sensitivity: \", recall_test)\n",
    "print(\"Specificity: \", precision_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
